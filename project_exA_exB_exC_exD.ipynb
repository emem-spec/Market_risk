{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07f22636-62bc-4c6b-989b-31ddbf463ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f40f462-fb7a-48ba-99a8-0ed2463c7612",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"TD1.csv\", sep=\";\")\n",
    "df[\"Cours de Natixis\"] = df[\"Cours de Natixis\"].astype(str).str.replace(\",\", \".\").astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79eddbbb-3951-4327-b575-7aca6f935a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Cours de Natixis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02/01/2015</td>\n",
       "      <td>5.621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05/01/2015</td>\n",
       "      <td>5.424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06/01/2015</td>\n",
       "      <td>5.329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>07/01/2015</td>\n",
       "      <td>5.224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08/01/2015</td>\n",
       "      <td>5.453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Cours de Natixis\n",
       "0  02/01/2015             5.621\n",
       "1  05/01/2015             5.424\n",
       "2  06/01/2015             5.329\n",
       "3  07/01/2015             5.224\n",
       "4  08/01/2015             5.453"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb72e0c8-f79e-48b0-8cd9-13df00983fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Cours de Natixis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>21/12/2018</td>\n",
       "      <td>4.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>24/12/2018</td>\n",
       "      <td>4.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>27/12/2018</td>\n",
       "      <td>3.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>28/12/2018</td>\n",
       "      <td>4.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>31/12/2018</td>\n",
       "      <td>4.119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  Cours de Natixis\n",
       "1018  21/12/2018             4.045\n",
       "1019  24/12/2018             4.010\n",
       "1020  27/12/2018             3.938\n",
       "1021  28/12/2018             4.088\n",
       "1022  31/12/2018             4.119"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "066143be-3c9c-478f-9962-a00b70248414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1023 entries, 0 to 1022\n",
      "Data columns (total 2 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Date              1023 non-null   object \n",
      " 1   Cours de Natixis  1023 non-null   float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 16.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4229c6d-64aa-466b-ba6b-c47fd4c874f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], dayfirst=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d900e4ea-4c61-4b72-ad60-5852ce516cad",
   "metadata": {},
   "source": [
    "## Question A ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9413128b-cd1b-4854-ba16-d6d5e1a19433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Cours de Natixis</th>\n",
       "      <th>Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>2016-06-23</td>\n",
       "      <td>4.150</td>\n",
       "      <td>-0.171325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>2016-05-09</td>\n",
       "      <td>4.386</td>\n",
       "      <td>-0.069083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>2016-05-26</td>\n",
       "      <td>4.752</td>\n",
       "      <td>-0.061448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>3.643</td>\n",
       "      <td>-0.060664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>4.470</td>\n",
       "      <td>-0.058613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Cours de Natixis    Return\n",
       "377 2016-06-23             4.150 -0.171325\n",
       "344 2016-05-09             4.386 -0.069083\n",
       "357 2016-05-26             4.752 -0.061448\n",
       "404 2016-08-01             3.643 -0.060664\n",
       "276 2016-02-01             4.470 -0.058613"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = df[\"Cours de Natixis\"].values \n",
    "returns = (P[1:] - P[:-1]) / P[:-1]        #we calculate the daily returns using current price and previous price\n",
    "returns = np.append(returns, np.nan)\n",
    "\n",
    "df[\"Return\"] = returns\n",
    "\n",
    "df_date = df[(df[\"Date\"] >= \"2015-01-01\") & (df[\"Date\"] <= \"2016-12-31\")]    #we take only the data returns between january 2015 and december 2016\n",
    "\n",
    "df_sorted = df_date.sort_values(by = \"Return\", ascending = True)    #we sort the returns in increasing order\n",
    "\n",
    "df_sorted.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b323107f-bc30-45be-92ca-6268038b5602",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05  # probability level here we choosed 5%, just need to change it here to change it for other VaR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9604a1a5-4fa1-4de2-b44b-55662b7e5fd9",
   "metadata": {},
   "source": [
    "### Historical VaR ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "856cd5dd-af62-4bb4-9e07-0798af55733c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical VaR at 5.0%: -0.038933559035124875\n"
     ]
    }
   ],
   "source": [
    "returns = df_sorted[\"Return\"]\n",
    "\n",
    "returns_sorted=np.sort(returns)\n",
    "n=len(returns_sorted)\n",
    "\n",
    "# Find the index corresponding to the value of alpha. With a length n then the index is n*alpha. And so it will give the 95th percentile smallest value\n",
    "index_empirical = int(alpha * (n-1))   #we take n-1 and not n because indexes start at 0\n",
    "\n",
    "# Empirical VaR\n",
    "VaR_empirical = returns_sorted[index_empirical]\n",
    "\n",
    "print(f\"Empirical VaR at {alpha*100}%: {VaR_empirical:}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf2f472-4aba-4b28-9927-4148e6ea6af8",
   "metadata": {},
   "source": [
    "### Biweight VaR ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "785e4cac-d2ad-4f78-9746-71754c13e885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the calculated bandwidth is :  0.007250001157290293\n",
      "Biweight Kernel VaR at alpha :  0.05  VaR_kernel =  -0.03811674623640021\n"
     ]
    }
   ],
   "source": [
    "# we first start with calculating the bandwidth, first we start by finding the standard deviation\n",
    "expectation = sum(returns)/n\n",
    "expecation_square=sum(returns**2)/n\n",
    "std=(expecation_square- expectation*expectation)**(1/2)\n",
    "\n",
    "h=((4*(std**5))/(3*n))**(1/5)\n",
    "\n",
    "print(\"the calculated bandwidth is : \", h)\n",
    "\n",
    "# now next step is to create a list of values that will be the potential VaR selected\n",
    "#so we create 10000 points going from minimum return to maximum returns and in those number will be the VaR we select using the Kernel method\n",
    "x_search = np.linspace(returns.min(), returns.max(), 10000)\n",
    "\n",
    "cdf = []\n",
    "\n",
    "for x in x_search :\n",
    "    #we know that in the kernel formula u = (x - Xi) / h\n",
    "    #so let's calculate u\n",
    "    u=(x-returns.values)/h\n",
    "    \n",
    "    #we start by putting only 0s in the kernel array. Then the values will change if u is between -1 and 1 or sup 1 and stay at 0 if u inf -1.\n",
    "    kernel=np.zeros_like(u)\n",
    "    #in the function we are given that the indicatrice is for |x|<1 (so x>= -1 and and x <= 1 (here x is u)\n",
    "    #first condition -1 <= u <= 1\n",
    "    indicatrice= (u>=-1)&(u<=1)\n",
    "    #so we consider only the value of x that are contained in that interval\n",
    "    val= u[indicatrice]\n",
    "\n",
    "    #now let's calculate the integral of K\n",
    "    # (1-x²)² = 1 - 2x² + x**4\n",
    "    #  Integral from - 1 to u (-1 because of the indicatrice and u because we calculate the cdf of K(u)\n",
    "    # so we can decompose in integral from -1 to 0 + integral from 0 to u. And since it is a cdf of a symetric function around 0 then integral from -1 to 0 = 0.5\n",
    "    # so integral from 0 to u is equal to u - 2/3 u**3 +1/5 u**5\n",
    "    kernel[indicatrice] = 0.5 + (15/16) * (val - (2/3)*val**3 + (1/5)*val**5)\n",
    "\n",
    "    #second condition u >1 then the cdf of K will be the integral on all the density function since it will be from -1 to u with indicatrice \n",
    "    #saying that u<1 so it become from - 1 to 1 and so the integral on all the density is equal to 1 by definition\n",
    "    kernel[u > 1] = 1.0\n",
    "    #now we take the average of the differente values of the kernel (1/n sum(kernel))\n",
    "    estimation = sum(kernel)/len(kernel)\n",
    "    cdf.append(estimation)\n",
    "    \n",
    "#we convert it to an array so we can substract alpha to each values of the cdf we calculated\n",
    "cdf = np.array(cdf)\n",
    "#we find the best argument\n",
    "idx_var = np.argmin(np.abs(cdf - alpha))\n",
    "#and finally we use this argument to find which value generated was the best kernel VaR\n",
    "VaR_kernel = x_search[idx_var]\n",
    "\n",
    "print(\"Biweight Kernel VaR at alpha : \", alpha,\" VaR_kernel = \", VaR_kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb151d6c-a9eb-4905-ae44-d33715e8c19a",
   "metadata": {},
   "source": [
    "### b) Porportion of returns that exceeded between January 2017 and December 2018 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34bccf42-bf1b-474a-87fc-11af6a104299",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_newdate=df[ (df[\"Date\"]<=\"2018-12-31\") & (df[\"Date\"] >= \"2017-01-01\")]  #we make a new dataset with this time the returns \n",
    "#between January 2017 and December 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c722dd09-962b-460c-a73a-730f87c66442",
   "metadata": {},
   "outputs": [],
   "source": [
    "#so we sort it again\n",
    "df_sorted2=df_newdate.sort_values(by = \"Return\", ascending=True) \n",
    "returns2=df_sorted2[\"Return\"]    \n",
    "returns2=returns2.dropna()\n",
    "returns2_sorted=np.sort(returns2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5ec6f8f-4e9c-4b35-8af4-3bed1db6fff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of days :  509\n",
      "exceptions :  8\n",
      "the proportion that exceeded the VaR of the Kernel 0.015717092337917484\n"
     ]
    }
   ],
   "source": [
    "exceptions = returns2<=VaR_kernel   #we check for the values that are below the Kernel VaR calculated\n",
    "n_exceptions=sum(exceptions)    #we count the how many there was\n",
    "proportion=n_exceptions/len(returns2_sorted)          #we divided by the number of total returns in the time desired\n",
    "print(\"number of days : \",len(returns2_sorted))\n",
    "print(\"exceptions : \", n_exceptions)\n",
    "print(\"the proportion that exceeded the VaR of the Kernel\", proportion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1a7b8d-d493-4d82-b149-1db8c745fd92",
   "metadata": {},
   "source": [
    "A proportion of 0.0157 mean that 1.57% of the values were below the value. This means that  in the following years (january 2017 to december 2018) the natixis stocks had less spikes in the losses, since we compared with the 5% worst case considering January 2015 to December 2016. We can note that the market for natixis was less volatil and risky in 2017/2018.\n",
    "The probability we aimed to get was 5% hence we didn't get the result we expected as 1.57% is pretty far from 5%. The model overestimate the risk. It is a bit too safe and conservative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17155eb-f183-4d5d-a6c6-2178e7136468",
   "metadata": {},
   "source": [
    "And now let's do the same but with empirical VaR to see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9200ab10-3caf-4c65-9378-fa6accf93227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of days :  509\n",
      "exceptions :  8\n",
      "the proportion that exceeded the VaR of the Kernel 0.015717092337917484\n"
     ]
    }
   ],
   "source": [
    "exceptions = returns2<=VaR_empirical   #we check for the values that are below the Kernel VaR calculated\n",
    "n_exceptions=sum(exceptions)    #we count the how many there was\n",
    "proportion=n_exceptions/len(returns2_sorted)          #we divided by the number of total returns in the time desired\n",
    "print(\"number of days : \",len(returns2_sorted))\n",
    "print(\"exceptions : \", n_exceptions)\n",
    "print(\"the proportion that exceeded the VaR of the Kernel\", proportion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022ed42e-a12f-4d47-8960-a4e92737d4a6",
   "metadata": {},
   "source": [
    "And so apparently we got the same result even tho the empirical VaR was equal to -0.0389 and so was lower so could have expected maybe one or less exceptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd9ac22-273b-4996-b939-43f7d1e3a539",
   "metadata": {},
   "source": [
    "## Question B ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0100cc95-9ad3-402b-8f75-fbf7d9ee24d2",
   "metadata": {},
   "source": [
    "### Expected Shortfall ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd42b4e1-7aa5-4411-995a-7a9b56058569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.053361818150455334\n"
     ]
    }
   ],
   "source": [
    "exceptions_kernel = df_sorted[\"Return\"][df[\"Return\"]<=VaR_kernel]\n",
    "\n",
    "Expected_Shortfall_kernel=sum(exceptions_kernel)/len(exceptions_kernel)\n",
    "print(Expected_Shortfall_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e37b3f0-3887-410a-b5f5-c0915f1473c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.053361818150455334\n"
     ]
    }
   ],
   "source": [
    "exceptions_empirical = df_sorted[\"Return\"][df[\"Return\"]<=VaR_empirical]\n",
    "\n",
    "Expected_Shortfall_empirical=sum(exceptions_empirical)/len(exceptions_empirical)\n",
    "print(Expected_Shortfall_empirical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931e2a01-745f-4a5b-941e-c918edc3a4e0",
   "metadata": {},
   "source": [
    "The expected shortfall is always lower (or equal in some special cases) than the VaR because it is the average of the returns below the VaR treshold. So the average of smaller values will always be smaller than the initial treshold\n",
    "\n",
    "In other words, the Expected Shortfall is the average of the worst values below the confidence interval alpha (here 5%) meanwhile VaR is just the 5% worst value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52b9ca9-6d80-46f9-9d5f-92c1601576ab",
   "metadata": {},
   "source": [
    "## Question C ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "684eea1a-fb15-4662-89c0-fd90fd81f85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"TD1.csv\", sep=\";\")\n",
    "df[\"Cours de Natixis\"] = df[\"Cours de Natixis\"].astype(str).str.replace(\",\", \".\").astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a0ff04d9-6ac9-4884-b659-efd3913b5863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Cours de Natixis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02/01/2015</td>\n",
       "      <td>5.621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05/01/2015</td>\n",
       "      <td>5.424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06/01/2015</td>\n",
       "      <td>5.329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>07/01/2015</td>\n",
       "      <td>5.224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08/01/2015</td>\n",
       "      <td>5.453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Cours de Natixis\n",
       "0  02/01/2015             5.621\n",
       "1  05/01/2015             5.424\n",
       "2  06/01/2015             5.329\n",
       "3  07/01/2015             5.224\n",
       "4  08/01/2015             5.453"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f8fc8344-9cff-4a1b-88c7-9f76e1452979",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f917823f-d2cc-452d-8be1-18d834c9fe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = df[\"Cours de Natixis\"].values \n",
    "returns = (P[1:] - P[:-1]) / P[:-1]  #we calculate the daily returns using current price and previous price\n",
    "returns = np.append(returns, np.nan)\n",
    "\n",
    "df[\"Return\"] = returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "57311cca-654c-4f56-9a14-a2fd6fde93a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns_sorted = np.sort(df[\"Return\"].values)  #we sort the returns in increasing order\n",
    "\n",
    "#seperate the returns into loss and gains (so negative and positive values)\n",
    "losses = returns_sorted[returns_sorted < 0]  \n",
    "gains = returns_sorted[returns_sorted > 0]\n",
    "\n",
    "#and we take the absolute values of the losses (also we sort them again since taking the absolute value of negative numbers changer there order)\n",
    "abs_losses = np.abs(losses)\n",
    "abs_losses = np.sort(abs_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "9741f7ee-6ed8-466b-936d-67d25de98501",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(losses) #we take the number of losses\n",
    "k = int(np.sqrt(n))  #k is a function such that k(n)/n tend to 0 when n tend to infinity so for example sqrt(n) work and also k(n) tend to infinity\n",
    "#now we have the formula of a pickand estimator with abs_losses[-k] representing X_n-k(n)+1:n. This one is for the loss so we take the absolut losses\n",
    "pickands_losses = (1 / np.log(2)) * np.log((abs_losses[-k] - abs_losses[-2*k]) / (abs_losses[-2*k] - abs_losses[-4*k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "f704ae00-49a1-4e7c-a421-9289066cdab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4081905706152293\n"
     ]
    }
   ],
   "source": [
    "print(pickands_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "de72a5a9-ded5-4c77-8bc3-26fb897f80a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gain=len(gains) #this time it is the number of gains\n",
    "k_gain=int(np.sqrt(n_gain)) #k is a function such that k(n)/n tend to 0 when n tend to infinity so for example sqrt(n) work and also k(n) tend to infinity\n",
    "#now we have the formula of a pickand estimator with abs_losses[-k] representing X_n-k(n)+1:n. This one is for the gains so we take the gains\n",
    "pickands_gains=(1 / np.log(2)) * np.log((gains[-k_gain] - gains[-2*k_gain]) / (gains[-2*k_gain] - gains[-4*k_gain]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "33c40ae5-803f-4b2d-8a4a-bb03e6404a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7195506129332101\n"
     ]
    }
   ],
   "source": [
    "print(pickands_gains)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a29ce6-2ff3-4432-b56c-d816da5444d5",
   "metadata": {},
   "source": [
    "Since we have both xi > 0 the distribution of Natixis returns belongs to the Fréchet domain. It means that the returns have an heavy tail, which mean that extreme events are more likely than in a normal distribution\n",
    "We can also note an asymmetry since the xi gain is > xi losses. This mean that the right tail is even heavier than the left tail. So it mean there was more extreme upside jump than crashes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935cd6b9-a99a-4e67-9970-613a154a9fb6",
   "metadata": {},
   "source": [
    "### b) VaR Pickand ###\n",
    "now that we have the pickand estimaro we can calculate the VaR based on EVT for various confidence levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "f624cfd3-ff6d-47b7-8f31-f01da496438f",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.95\n",
    "#we use the formula from the course to calculate VaR thanks to the pickand estimator (here we use the pickand loss)\n",
    "VaR_95 = ((((k / (n * (1 - alpha))) ** pickands_losses) - 1)/ (1 - 2 ** (-pickands_losses))) * (abs_losses[-k] - abs_losses[-2 * k]) + abs_losses[-k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "8a613d4d-92f8-4fe4-9bde-fd73735b262d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.041879473608224776\n"
     ]
    }
   ],
   "source": [
    "print(VaR_95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d606ec58-0718-4dee-97ac-66444b901b94",
   "metadata": {},
   "source": [
    "This VaR (0.0418) is higher than the Historical VaR (0.0389) that we found in question A. This is probably because the historical VaR assume that the future will look like the past. Meanwhile the EVT uses the properties of the heavy tail (since xi=0.41>0) to kind of extend the tail risk and so increase the VaR (increase the potential loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "c4520a44-c212-4499-8aa2-62d0393f0618",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.9\n",
    "\n",
    "VaR_90 = ((((k / (n * (1 - alpha))) ** pickands_losses) - 1)/ (1 - 2 ** (-pickands_losses))) * (abs_losses[-k] - abs_losses[-2 * k]) + abs_losses[-k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "9c31dd6e-d5e7-4137-b052-2d6aad4eed2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.030899922464728252\n"
     ]
    }
   ],
   "source": [
    "print(VaR_90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "74612bfe-c6b8-4460-b094-510c27b3d452",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.99\n",
    "\n",
    "VaR_99 = ((((k / (n * (1 - alpha))) ** pickands_losses) - 1)/ (1 - 2 ** (-pickands_losses))) * (abs_losses[-k] - abs_losses[-2 * k]) + abs_losses[-k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "df824e17-824d-4528-acc5-8521e7d51ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08326638673655591\n"
     ]
    }
   ],
   "source": [
    "print(VaR_99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c53d60-b561-4bce-8e8e-bef325cbec2c",
   "metadata": {},
   "source": [
    "## Question D ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ad15d36-b77f-4408-92cf-438ff26b0ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_D=pd.read_excel(\"Dataset TD4.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d744751-4648-4918-a39a-65511cc94175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction date (1=1day=24 hours)</th>\n",
       "      <th>bid-ask spread</th>\n",
       "      <th>volume of the transaction (if known)</th>\n",
       "      <th>Sign of the transaction</th>\n",
       "      <th>Price (before transaction)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001070</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>99.984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001496</td>\n",
       "      <td>0.1015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>100.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003336</td>\n",
       "      <td>0.0920</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>99.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003952</td>\n",
       "      <td>0.1106</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>100.060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   transaction date (1=1day=24 hours)  bid-ask spread  \\\n",
       "0                            0.000202          0.1100   \n",
       "1                            0.001070          0.1030   \n",
       "2                            0.001496          0.1015   \n",
       "3                            0.003336          0.0920   \n",
       "4                            0.003952          0.1106   \n",
       "\n",
       "   volume of the transaction (if known)  Sign of the transaction  \\\n",
       "0                                   8.0                       -1   \n",
       "1                                   NaN                        1   \n",
       "2                                   NaN                       -1   \n",
       "3                                   NaN                        1   \n",
       "4                                   NaN                        1   \n",
       "\n",
       "   Price (before transaction)  \n",
       "0                     100.000  \n",
       "1                      99.984  \n",
       "2                     100.029  \n",
       "3                      99.979  \n",
       "4                     100.060  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_D.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c8170de9-5c9f-4db8-93f8-11cca3972e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_D[\"Price change\"] = df_D[\"Price (before transaction)\"].shift(-1) - df_D[\"Price (before transaction)\"]    \n",
    "#we create a new column with the variation of prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca218688-b4c3-426e-86fb-fefc0edef2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1001 entries, 0 to 1000\n",
      "Data columns (total 6 columns):\n",
      " #   Column                                Non-Null Count  Dtype  \n",
      "---  ------                                --------------  -----  \n",
      " 0   transaction date (1=1day=24 hours)    1001 non-null   float64\n",
      " 1   bid-ask spread                        1001 non-null   float64\n",
      " 2   volume of the transaction (if known)  137 non-null    float64\n",
      " 3   Sign of the transaction               1001 non-null   int64  \n",
      " 4   Price (before transaction)            1001 non-null   float64\n",
      " 5   Price change                          1000 non-null   float64\n",
      "dtypes: float64(5), int64(1)\n",
      "memory usage: 47.1 KB\n"
     ]
    }
   ],
   "source": [
    "df_D.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3639b2cb-43db-4875-9c5e-1e782518cdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We drop the lines where we don't know the real volume\n",
    "# We also drop the last row that is nan because of the shift and the row where price is equal to 0\n",
    "df_bouchaud = df_D.dropna(subset=[\"volume of the transaction (if known)\", \"Price change\"]).copy()\n",
    "df_bouchaud = df_bouchaud[df_bouchaud[\"Price change\"] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e1cf3ea5-dff7-4953-a4c9-edd0251cfbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the formula of the y is |price change| = c*Volume^gamma and so if take the ln, ln(|price change|) = ln(c) + gamma*ln(Volume)\n",
    "y_target_log = np.log(np.abs(df_bouchaud[\"Price change\"])).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd459214-197c-4991-9441-0045f875b044",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_log = np.log(df_bouchaud[\"volume of the transaction (if known)\"]).values\n",
    "n_bouchaud = len(X_log)  #creating a vector of one of size X\n",
    "ones_bouchaud = np.ones(n_bouchaud)  #we create a vector of ones that will be added to the X matrix so we can have the \"intercept\" that is c here\n",
    "X_log_matrix = np.column_stack((ones_bouchaud, X_log)) #merging the vector of one and the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9fccd7c5-a02f-40e2-92f4-33239e48b725",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_bouchaud = np.linalg.inv(X_log_matrix.T@X_log_matrix)@X_log_matrix.T@y_target_log #formula for beta = (X^tX)^(-1)X^tY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5da42559-d344-40d1-b58e-6e2a18cd8337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.60581795  0.63478629]\n"
     ]
    }
   ],
   "source": [
    "print(beta_bouchaud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "bd68b188-27f9-4145-afe0-cb9f1b857dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c the impact coefficient is :  0.003676412179209437\n",
      "gamma the volume exponent is :  0.6347862887489955\n"
     ]
    }
   ],
   "source": [
    "#we extract the parameters\n",
    "ln_c=beta_bouchaud[0]\n",
    "gamma=beta_bouchaud[1]\n",
    "c=np.exp(ln_c)\n",
    "print(\"c the impact coefficient is : \", c)\n",
    "print(\"gamma the volume exponent is : \", gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa78b57-af0b-487a-a032-a29ff399b5dd",
   "metadata": {},
   "source": [
    "The resut of gamma means that the change in price isn't lineary correlated to the change in volume (for this would have needed gamma=1)\n",
    "In our context it means that for example if we double the volume of the transaction it will have a price variation of 2^gamma (2^0.634=1.55)\n",
    "This confirms that the impact of volume on price change is a concave function, larger trades move the price less per unit of volume than small trades, which makes the market more resilient to large orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a479db43-2015-4b57-8ada-b5a71d5483a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = df_D['Price (before transaction)'].values\n",
    "signs = df_D['Sign of the transaction'].values\n",
    "lags = np.arange(1, 101)\n",
    "R_l = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "bf34b54a-32fa-4e3f-b450-322019eb7e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in lags:\n",
    "    # Calculate Price difference between time t+l and t\n",
    "    # prices[l:] corresponds to P_{t+l}\n",
    "    # prices[:-l] corresponds to P_t\n",
    "    delta_p = prices[l:] - prices[:-l]\n",
    "    \n",
    "    # Get the corresponding signs at time t\n",
    "    signs_t = signs[:-l]\n",
    "    \n",
    "    # The response function is the average of (P_{t+l} - P_t) * sign_t\n",
    "    # It measures how much a buy/sell order at time t influences the price l steps later\n",
    "    response = np.nanmean(delta_p * signs_t)\n",
    "    R_l.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5aba1c37-2b0a-4d37-ab3a-470db88afd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_l = np.array(R_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5f4d6420-6475-437a-ae1a-16b0f182e5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We assume that it follows R(l) ~ A * l^xi\n",
    "# And so we do a log regression: ln(R(l)) = ln(A) + xi * ln(l)\n",
    "valid_indices = R_l > 0\n",
    "log_l = np.log(lags[valid_indices])\n",
    "log_R = np.log(R_l[valid_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f398bb0e-697b-490e-a024-a45b5c7f2796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare matrix for linear regression (Intercept + Slope)\n",
    "n_log=len(log_l)\n",
    "ones_log=np.ones(n_log)\n",
    "X_mat = np.column_stack((ones_log, log_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b60fe8d9-0e67-47cd-b8a6-d84a037022e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_2 = np.linalg.inv(X_mat.T @ X_mat) @ X_mat.T @ log_R   #formula for beta = (X^tX)^(-1)X^tY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "77284a68-b347-4c22-bf78-3a2535a9eb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we extract the parameters\n",
    "ln_A=beta_2[0]\n",
    "A=np.exp(ln_A)\n",
    "xi = beta_2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "300f7a41-892a-4137-b556-015dc0876956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decay amplitude :  0.16143682144630483\n",
      "Propagator Decay Parameters\n",
      "Estimated Response Exponent :  -0.4266974247786012\n"
     ]
    }
   ],
   "source": [
    "print(\"Decay amplitude : \",A)\n",
    "print(\"Propagator Decay Parameters\")\n",
    "print(\"Estimated Response Exponent : \", xi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb4c453-dfbd-4554-aef5-ca58202aae78",
   "metadata": {},
   "source": [
    "When a trade happen it move the price instantly (this is seen with gamma and lambda) but it also has some impact over time (this is seen with the exponent parameter xi). -0.427 mean that the price impact is temporary and that the market pushes the price back after a trade occurs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c861a3a-13dc-4eba-9939-d062888acb23",
   "metadata": {},
   "source": [
    "So to answer is the result well specified? Yes it is because gamma = 0.63 which is close to the expected 0.5, so it is relatively well specified. And it is expected for xi to be negative and non zero because it confirm that the market has memory but the impact of this memory decay over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa6b368-623a-43e4-a6fa-d0beb871140e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ca301b-8219-45b3-b984-1704f05af34a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4372cae-b174-43cc-a5bc-ece3771193b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07b1db0-97d3-4fa9-8241-205d4f67c520",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5d6147-434f-47f2-a994-3ee7e31ddcad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50efb7b2-ad48-4cd3-9545-0180ff2b0cca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
