{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "07f22636-62bc-4c6b-989b-31ddbf463ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "2f40f462-fb7a-48ba-99a8-0ed2463c7612",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"TD1.csv\", sep=\";\")\n",
    "df[\"Cours de Natixis\"] = df[\"Cours de Natixis\"].astype(str).str.replace(\",\", \".\").astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "79eddbbb-3951-4327-b575-7aca6f935a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Cours de Natixis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02/01/2015</td>\n",
       "      <td>5.621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05/01/2015</td>\n",
       "      <td>5.424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06/01/2015</td>\n",
       "      <td>5.329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>07/01/2015</td>\n",
       "      <td>5.224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08/01/2015</td>\n",
       "      <td>5.453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Cours de Natixis\n",
       "0  02/01/2015             5.621\n",
       "1  05/01/2015             5.424\n",
       "2  06/01/2015             5.329\n",
       "3  07/01/2015             5.224\n",
       "4  08/01/2015             5.453"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "fb72e0c8-f79e-48b0-8cd9-13df00983fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Cours de Natixis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>21/12/2018</td>\n",
       "      <td>4.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>24/12/2018</td>\n",
       "      <td>4.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>27/12/2018</td>\n",
       "      <td>3.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>28/12/2018</td>\n",
       "      <td>4.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>31/12/2018</td>\n",
       "      <td>4.119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  Cours de Natixis\n",
       "1018  21/12/2018             4.045\n",
       "1019  24/12/2018             4.010\n",
       "1020  27/12/2018             3.938\n",
       "1021  28/12/2018             4.088\n",
       "1022  31/12/2018             4.119"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "066143be-3c9c-478f-9962-a00b70248414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1023 entries, 0 to 1022\n",
      "Data columns (total 2 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Date              1023 non-null   object \n",
      " 1   Cours de Natixis  1023 non-null   float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 16.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e4229c6d-64aa-466b-ba6b-c47fd4c874f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], dayfirst=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d900e4ea-4c61-4b72-ad60-5852ce516cad",
   "metadata": {},
   "source": [
    "## Question A ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "9413128b-cd1b-4854-ba16-d6d5e1a19433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Cours de Natixis</th>\n",
       "      <th>Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>2016-06-23</td>\n",
       "      <td>4.150</td>\n",
       "      <td>-0.171325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>2016-05-09</td>\n",
       "      <td>4.386</td>\n",
       "      <td>-0.069083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>2016-05-26</td>\n",
       "      <td>4.752</td>\n",
       "      <td>-0.061448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>3.643</td>\n",
       "      <td>-0.060664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>4.470</td>\n",
       "      <td>-0.058613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Cours de Natixis    Return\n",
       "377 2016-06-23             4.150 -0.171325\n",
       "344 2016-05-09             4.386 -0.069083\n",
       "357 2016-05-26             4.752 -0.061448\n",
       "404 2016-08-01             3.643 -0.060664\n",
       "276 2016-02-01             4.470 -0.058613"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = df[\"Cours de Natixis\"].values \n",
    "returns = (P[1:] - P[:-1]) / P[:-1]        #we calculate the daily returns using current price and previous price\n",
    "returns = np.append(returns, np.nan)\n",
    "\n",
    "df[\"Return\"] = returns\n",
    "\n",
    "df_date = df[(df[\"Date\"] >= \"2015-01-01\") & (df[\"Date\"] <= \"2016-12-31\")]    #we take only the data returns between january 2015 and december 2016\n",
    "\n",
    "df_sorted = df_date.sort_values(by = \"Return\", ascending = True)    #we sort the returns in increasing order\n",
    "\n",
    "df_sorted.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "b323107f-bc30-45be-92ca-6268038b5602",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05  # probability level here we choosed 5%, just need to change it here to change it for other VaR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9604a1a5-4fa1-4de2-b44b-55662b7e5fd9",
   "metadata": {},
   "source": [
    "### Historical VaR ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "856cd5dd-af62-4bb4-9e07-0798af55733c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical VaR at 5.0%: -0.038933559035124875\n"
     ]
    }
   ],
   "source": [
    "returns = df_sorted[\"Return\"]\n",
    "\n",
    "returns_sorted=np.sort(returns)\n",
    "n=len(returns_sorted)\n",
    "\n",
    "# Find the index corresponding to the value of alpha. With a length n then the index is n*alpha. And so it will give the 95th percentile smallest value\n",
    "index_empirical = int(alpha * (n-1))   #we take n-1 and not n because indexes start at 0\n",
    "\n",
    "# Empirical VaR\n",
    "VaR_empirical = returns_sorted[index_empirical]\n",
    "\n",
    "print(f\"Empirical VaR at {alpha*100}%: {VaR_empirical:}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf2f472-4aba-4b28-9927-4148e6ea6af8",
   "metadata": {},
   "source": [
    "### Biweight VaR ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "785e4cac-d2ad-4f78-9746-71754c13e885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the calculated bandwidth is :  0.007250001157290293\n",
      "Biweight Kernel VaR at alpha :  0.05  VaR_kernel =  -0.03811674623640021\n"
     ]
    }
   ],
   "source": [
    "# we first start with calculating the bandwidth, first we start by finding the standard deviation\n",
    "expectation = sum(returns)/n\n",
    "expecation_square=sum(returns**2)/n\n",
    "std=(expecation_square- expectation*expectation)**(1/2)\n",
    "\n",
    "h=((4*(std**5))/(3*n))**(1/5)\n",
    "\n",
    "print(\"the calculated bandwidth is : \", h)\n",
    "\n",
    "# now next step is to create a list of values that will be the potential VaR selected\n",
    "#so we create 10000 points going from minimum return to maximum returns and in those number will be the VaR we select using the Kernel method\n",
    "x_search = np.linspace(returns.min(), returns.max(), 10000)\n",
    "\n",
    "cdf = []\n",
    "\n",
    "for x in x_search :\n",
    "    #we know that in the kernel formula u = (x - Xi) / h\n",
    "    #so let's calculate u\n",
    "    u=(x-returns.values)/h\n",
    "    \n",
    "    #we start by putting only 0s in the kernel array. Then the values will change if u is between -1 and 1 or sup 1 and stay at 0 if u inf -1.\n",
    "    kernel=np.zeros_like(u)\n",
    "    #in the function we are given that the indicatrice is for |x|<1 (so x>= -1 and and x <= 1 (here x is u)\n",
    "    #first condition -1 <= u <= 1\n",
    "    indicatrice= (u>=-1)&(u<=1)\n",
    "    #so we consider only the value of x that are contained in that interval\n",
    "    val= u[indicatrice]\n",
    "\n",
    "    #now let's calculate the integral of K\n",
    "    # (1-x²)² = 1 - 2x² + x**4\n",
    "    #  Integral from - 1 to u (-1 because of the indicatrice and u because we calculate the cdf of K(u)\n",
    "    # so we can decompose in integral from -1 to 0 + integral from 0 to u. And since it is a cdf of a symetric function around 0 then integral from -1 to 0 = 0.5\n",
    "    # so integral from 0 to u is equal to u - 2/3 u**3 +1/5 u**5\n",
    "    kernel[indicatrice] = 0.5 + (15/16) * (val - (2/3)*val**3 + (1/5)*val**5)\n",
    "\n",
    "    #second condition u >1 then the cdf of K will be the integral on all the density function since it will be from -1 to u with indicatrice \n",
    "    #saying that u<1 so it become from - 1 to 1 and so the integral on all the density is equal to 1 by definition\n",
    "    kernel[u > 1] = 1.0\n",
    "    #now we take the average of the differente values of the kernel (1/n sum(kernel))\n",
    "    estimation = sum(kernel)/len(kernel)\n",
    "    cdf.append(estimation)\n",
    "    \n",
    "#we convert it to an array so we can substract alpha to each values of the cdf we calculated\n",
    "cdf = np.array(cdf)\n",
    "#we find the best argument\n",
    "idx_var = np.argmin(np.abs(cdf - alpha))\n",
    "#and finally we use this argument to find which value generated was the best kernel VaR\n",
    "VaR_kernel = x_search[idx_var]\n",
    "\n",
    "print(\"Biweight Kernel VaR at alpha : \", alpha,\" VaR_kernel = \", VaR_kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb151d6c-a9eb-4905-ae44-d33715e8c19a",
   "metadata": {},
   "source": [
    "### b) Porportion of returns that exceeded between January 2017 and December 2018 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "34bccf42-bf1b-474a-87fc-11af6a104299",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_newdate=df[ (df[\"Date\"]<=\"2018-12-31\") & (df[\"Date\"] >= \"2017-01-01\")]  #we make a new dataset with this time the returns \n",
    "#between January 2017 and December 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "c722dd09-962b-460c-a73a-730f87c66442",
   "metadata": {},
   "outputs": [],
   "source": [
    "#so we sort it again\n",
    "df_sorted2=df_newdate.sort_values(by = \"Return\", ascending=True) \n",
    "returns2=df_sorted2[\"Return\"]    \n",
    "returns2=returns2.dropna()\n",
    "returns2_sorted=np.sort(returns2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "f5ec6f8f-4e9c-4b35-8af4-3bed1db6fff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of days :  509\n",
      "exceptions :  8\n",
      "the proportion that exceeded the VaR of the Kernel 0.015717092337917484\n"
     ]
    }
   ],
   "source": [
    "exceptions = returns2<=VaR_kernel   #we check for the values that are below the Kernel VaR calculated\n",
    "n_exceptions=sum(exceptions)    #we count the how many there was\n",
    "proportion=n_exceptions/len(returns2_sorted)          #we divided by the number of total returns in the time desired\n",
    "print(\"number of days : \",len(returns2_sorted))\n",
    "print(\"exceptions : \", n_exceptions)\n",
    "print(\"the proportion that exceeded the VaR of the Kernel\", proportion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1a7b8d-d493-4d82-b149-1db8c745fd92",
   "metadata": {},
   "source": [
    "A proportion of 0.0157 mean that 1.57% of the values were below the value. This means that  in the following years (january 2017 to december 2018) the natixis stocks had less spikes in the losses, since we compared with the 5% worst case considering January 2015 to December 2016. We can note that the market for natixis was less volatil and risky in 2017/2018.\n",
    "The probability we aimed to get was 5% hence we didn't get the result we expected as 1.57% is pretty far from 5%. The model overestimate the risk. It is a bit too safe and conservative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17155eb-f183-4d5d-a6c6-2178e7136468",
   "metadata": {},
   "source": [
    "And now let's do the same but with empirical VaR to see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "9200ab10-3caf-4c65-9378-fa6accf93227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of days :  509\n",
      "exceptions :  8\n",
      "the proportion that exceeded the VaR of the Kernel 0.015717092337917484\n"
     ]
    }
   ],
   "source": [
    "exceptions = returns2<=VaR_empirical   #we check for the values that are below the Kernel VaR calculated\n",
    "n_exceptions=sum(exceptions)    #we count the how many there was\n",
    "proportion=n_exceptions/len(returns2_sorted)          #we divided by the number of total returns in the time desired\n",
    "print(\"number of days : \",len(returns2_sorted))\n",
    "print(\"exceptions : \", n_exceptions)\n",
    "print(\"the proportion that exceeded the VaR of the Kernel\", proportion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022ed42e-a12f-4d47-8960-a4e92737d4a6",
   "metadata": {},
   "source": [
    "And so apparently we got the same result even tho the empirical VaR was equal to -0.0389 and so was lower so could have expected maybe one or less exceptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd9ac22-273b-4996-b939-43f7d1e3a539",
   "metadata": {},
   "source": [
    "## Question B ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0100cc95-9ad3-402b-8f75-fbf7d9ee24d2",
   "metadata": {},
   "source": [
    "### Expected Shortfall ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "dd42b4e1-7aa5-4411-995a-7a9b56058569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.053361818150455334\n"
     ]
    }
   ],
   "source": [
    "exceptions_kernel = df_sorted[\"Return\"][df[\"Return\"]<=VaR_kernel]\n",
    "\n",
    "Expected_Shortfall_kernel=sum(exceptions_kernel)/len(exceptions_kernel)\n",
    "print(Expected_Shortfall_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "7e37b3f0-3887-410a-b5f5-c0915f1473c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.053361818150455334\n"
     ]
    }
   ],
   "source": [
    "exceptions_empirical = df_sorted[\"Return\"][df[\"Return\"]<=VaR_empirical]\n",
    "\n",
    "Expected_Shortfall_empirical=sum(exceptions_empirical)/len(exceptions_empirical)\n",
    "print(Expected_Shortfall_empirical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931e2a01-745f-4a5b-941e-c918edc3a4e0",
   "metadata": {},
   "source": [
    "The expected shortfall is always lower (or equal in some special cases) than the VaR because it is the average of the returns below the VaR treshold. So the average of smaller values will always be smaller than the initial treshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116f7e02-2414-49e8-b9ee-3e6f2823f5b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
